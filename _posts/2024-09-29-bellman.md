---
layout: post
read_time: true
show_date: true
title:  Bellman Equation
date:   2024-09-29
description: Bellman Equation
img: posts/20210210/Game_of_Life.jpg
tags: [RL, coding]
author: 
github:  
mathjax: yes
---

### 벨만 방정식
: 시점 t에서의 밸류와 시점 t+1에서의 밸류 사이의 관계를 다루고 있으며 또 가치 함수와 정책 함수 사이의 관계도 다룸. 무언가 정책이 주어지고, 그 정책을 평가하고 싶을 때 이용.

0단계: 현재 상태의 밸류와 다음 상태의 밸류 사이의 관계를 나타냄

1단계:
2단계:

모델-프리: MDP에 대한 정보를 모를때, 실제로 상태s에서 액션a를 해서 학습하는 접근법(0단계 식)
모델 기반 플래닝: 보상함수와 전이 확률을 다 안다면 실제로 경험해보지 않고 시뮬레이션하는 접근법(2단계 식)

### 벨만 최적 방정식
부분 순서(partial ordering): 전체 중에 일부만 대소관계르 비교하여 순서를 정할수 있다.
최적의 밸류를 찾는 일을 할 때 사용.

MDP내의 모든 $\pi$에 대해 $\pi_* > \pi$를 만족하는 $\pi_*$가 반드시 존재

0단계:
1단계:
2단계:

\$pi$에 의한 확률적 요소가 사라짐. 액션을 선택할 때 확룰적이로 선택하는 것이 아니라 최대값 연산자를 통해 제일 좋은 액션을 선택

