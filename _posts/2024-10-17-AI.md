---
layout: post
read_time: true
show_date: true
title:  AI
date:   2024-10-01
description: Planning
img: posts/20210324/starting_adventure.jpg
tags: [RL]
author: 
github:  
mathjax: yes
---




-------------------------- 1, 2 -------------------  
novel: 새로운  
fidelity: 충실함, 동등  
rationality: 합리성  
sufficient: 구현 가능한, 충분한  
perceptual: 지각있는  
perceive: 인지하다  
inference: 추론  
priori: 선험적인  
vast: 방대한  
nondeterministic: 확률값 없이 예측  
deliberating: 계획적인, 신중한  
utility function: 효용함수  
derive: 끌어내다, 유래하다  

-------- 3 ----------------  
anomaly: 이상치  
supervised  
unsupervised  
reinforcement learning  
exclusive: 배타적인  
ambiguous: 모호한  
denote: 의미하다  
posteriori: 사후  
arguably: 틀림없이  
typical: 대표적인  
nontrivial: 중요한, 자명한  
latent: 숨어있는, 잠재된  
infer: 결론을 도출하다, 추론하다  
reduction: 축소  
variability: 가변성  
ICA(Independent Component Analysis):  
PCA:  
empirical:   
indicator function:  
curse: 저주  
residual error: 선형예측과 실제값의 계산상 오차  

다양한 예에 적용하기위해 비선형 모델을 이용  
가우시안 분포  
베르누이 분포  
e.g. : 예를 들어  
c.f. : 비교하다  
KNN: K를 증가시켜서 훈련 set에서 오차율을 증가시킴
cross validation  

--------------- 4 ----------------  
r.v. (random variables)  
for short: 생략하여  
pmf: 확률질량함수  
배타적  
독립적  
joint probabilities: 결합확률  
marginal distribution: 주변확률분포. 결합분포에서 원하는 하나의 확률변수를 선택하고, 나머지 확률변수에 대해서는 모든 가능한 값들의 합 또는 적분을 통해 구함  
arbitrary: 임의의  
discriminative classifier 판별형 분류기  
CI(conditionalyy independent)  
cdf(cumulative disribution function) 누적 분포 함수  
monotonically: 단조롭게, 꾸준히  
pdf: probability density function  
inverse F: 역함수  
최소자승법의 위험을 방지하고자 lasso이용  
시그마  
deviation: 편차  

----------------- 5-------------------------

sigmoid: 0과 1사이로 변환. 증가 함수  
tanh (hyperbolic tangent) -1과 1 사이로 변환. 증가함수  
Relu (rectified linear activation): 0 이상. 증가함수. 일부만 활성화시켜서 출력가능. 미분을 해야할 때 식을 간단하게 해줌.  
오메가:  regularizer  
empirical 경합할 수 있는  
surrogate: 대리  
epoch : a period of time in history or a person's life, typically one marked by notable events or particular characteristics
log-likelihood  
nature log  
cross-entropy  
chain rule:
L2 regularization: ridge(square) RMSE. 크기를 줄이는 것이 목적. 웨잇 디케잉  
L1 regularization: lasso 절대값(absolute) MAE. 대부분을 0으로 만드는 것이 목적. 스팔스

-----------------------6 ----------------------  
parameter sharing : path 안에 특정 패턴에 반응. hidden unit마다 다르게 가져가지 않고 공유할 수 있다.
이를 통해 pixel마다 같은 필터를 사용함으로써 파라미터를 줄일 수 있다.  
pooling: 옆으로 이동시 max값은 변하지 않을 확률이 높음.(max, average 통합)  
subsampling : 인근값으로 대표값을 출력
local connectivity: 모든 데이터에 대해 input으로 받아들이지 않고 인접한 데이터에 대해서만 input으로 받아들인다.
이를 통해 각 output은 모든 input을 고려하지 않고 적은 수의 input에 의해서만 결정될 수 있다.  
cnn:convolutional and pooling layers 번갈아 넣음. 이미지 및 비디오 처리를 위해 설계. 컨볼루션 레이어를 사용하여 입력 데이터에서 특징을 추출하고 풀링 레이어를 사용하여 출력의 차원을 줄임. CNN은 물체 인식 및 분할과 같이 공간적 이해가 필요한 작업에 적합
softmax: 둘 이상의 클래스가 존재하는 분류문제에 사용. 입력받은 값을 출력으로 0~1사이의 값으로 모두 정규화하며 출력 값들의 총합은 항상 1이 되는 특성을 가진 함수

--------------7 ----------------------------  
rnn: scale to much longer sequences. 계열이나 자연어와 같은 순차적인 데이터를 처리하도록 설계. 시간이 지나도 정보가 지속될 수 있는 피드백 루프가 있어 메모리가 필요한 작업에 적합.
shallow: 얕은, 피상적인  
unfolding  
backpropagation  

RNN의 경우 시퀀스가 너무 길다면 앞 쪽의 타임 스텝의 정보가 뒤에 있는 타입스텝까지 충분히 전달되지 못하는 문제가 있습니다. 이를 장기 의존성 문제(long-term dependecies)라고 함.   
gated uints: vanishing gradients, exploding gradient 를 막아줌(derivaative)으로써 가중치 조정(accumulation or forgetting)  
- LSTM(long short-term memory): LSTM: Forget gate, input gate, cell state update, output gate를 이용.  
gate들의 이름에서 알 수 있듯이 어떤 정보를 잊을지 유지할지를 선택하여 long term과 short term에 대한 정보를 고려.  
gate들과 함께 작용하여 정보를 선택적으로 활용할 수 있도록 하는 것입니다
- GRUs(gated recurrent units): GRU에서는 reset gate, update gate 2개의 gate만을 사용
 

------------------8------------------------  
RL: 특정 상황에서 정답을 주지 않음  
i.i.d. : independent and identically distributed  
markov state:  
POMDP(Partially observable Markov decision process)  
policy: the agent's behavior  
Value function: 최적 정책을 따랐을 때 최적의 가치함수와 특정 정책에 대한 가치함수(전체 state에 대한 가치)가 있다.
model: predict what environment will do next(각 state 마다 보상)  
exploitation: go to your favorite restaurant  
exploration: try a new restaurant  
prediction: evaluate the future (given a policy)
control: optimize the future (find the best policy)  
- 정책함수: 액션에 대한 확률분포로 어떤 액션을 선택할지 결정.
- 상태가치함수는 정책함수에 따라 에피소드를 진행할 때 얻은 누적 보상의 기대값으로 승률을 알 수 있다.

-------------- 1028 -----------------------------
regression 문제: 예측하려는 값이 연속적인 값인 경우  
multiple regression: 둘 이상의 feature를 이용해서 값을 예측  
univariate regression: 하나의 값만 예측  
regression의 성능척도  
- RMSE: root means squared error  
- MAE: mean absolute error  

train/test를 나눠서 범용적인 모델을 만들기 위함.단순히 무작위로 인스턴스를 나누게 되면 원 데이터가 갖고 있는 어떤 데이터 분포가 train/test set을 나누는 과정에서 왜곡될 수 있다. 
따라서 무작위로 선택을 하되 분포정보가 왜곡되지 않도록 해야한다.  
계층적 샘풀링: 원 데이터의 중위소득의 분포가 테스트 데이터에서도 가능한 그대로 유지하게끔 하는 것이 중요.  

cleaning 작업: 비정상 데이터는 제거하거나 다른 값으로 채워넣는 방식  
imputer:  
one-hot encoding: 카테고리형 변수를 벡터로 변환하기 위해 카테고리 수의 크기를 갖는 벡터를 만들고, 해당 카테고리에 해당하는 컴포넌트에는 1을 갖고 나머지에는 0을 갖는다.  

성능향상을 위해 수치를 스케일링 작업 필요.
- min-max 스케일링: nomalization 0 to 1
- standardization(표준화) 스케일링: 평균값으로 변환

preprocessing: 전처리(data cleaning과 scaling 작업)   
cross-validation  
grid search: 순차적으로 입력 > 좋은 하이퍼파라미터 찾기  

----------------------------- 1104 -------------------------  
interpolation: 보간  
K-fold cross-validation: 선택한 분류기(kogisticRegression)가 적합한 모델인지 판단  

데이터의 불균형을 고려하기 위해 사용  
- confusion matrix: 에러의 양상을 구체적으로 파악하기 위해서는 분류기가 어떤 입력을 어떤 방식으로 틀리는지 파악하기 위해 혼돈행렬을 이용  
- accuracy(정확도)  
- precision(정밀도): 참이라고 예측한 것중에 실제로 맞춘 것: tp/(tp+fp)  결과-예측  
- recall(재현율): 실제로 참인 것중 몇개를 맞춘것 : tp/(tp+fn)  
- F1-score: 성능 척도 precision과 recall의 조화 평균. 2 x (pr x re)/(pr + re)  
- ROC Curve: receiver operating characteristic curve tp rate과 fp rate를 동시에 시각화  
- AUC: area under the curve  

Random forest, Naive Bayes는 둘 이상의  class가 존재하는 분류뮨제에 적용 가능 모델  
SVM, Linear는 이진 클래스의 분류에만 적용 가능.  
one versus all(ovA) = one-versus-the-rest  
one versus one(ovo): 두 클래스를 분류하는 분류기를 클래스의 수 x (클래스의 수 -1)/2 개를 학습하고 duel에서 가장 많이 승리한 class를 선택  
multilabel classification: 각 입력이 둘 이상의 클래스를 갖는 것을 가정. 성능평가는 f1-score이용(각 label은 0-1 형태)  
multioutput classification: 멀티라벨보다 일반적인 문제로 label이 multi-class인 경우

------------------------ 1111 ------------------------------------------  
선형회귀: 학습방법(오차를 최소화하는 가중치를 찾는 것이 목표)
- direct "closed-form" equation
- iterative optimization approach: normal equation을 사용할 경우 계산복잡도가 실용적이지 안아서 반복기법 사용. 

Gradient Descent: cost function이 감소하는 방향으로 위치를 변경하면서 최소가 되는 위치를 찾기 위해 적용. learning step이 너무 작으면 수렴속도가 느려짐. 크면 지그재그 현상 발생.  
- batch gradient descent: 파라미터를 한 번 업데이트 하기 위해 전체 데이터를 이용. 데이터가 크면 계산량도 커짐.  반복 마다 전체 데이터의 gradient를 계산 시간이 오래 걸림. 
메모리의 양도 많다. local minimum에 빠지면 벗어나오기 힘들수도
- SGD(stochastic gradient descent) : 무작위로 샘플링한 하나의 데이터에 의한 에러함수의 gradient를 이용. 변동성이 커서 learning step 설정시 주의가 필요. 
loss값이 변동성이 커서 global minimum 에 다다르기 힘듬.  
- mini-batch gradient descent: 미리 정해진 개수의 데이터를 무작위로 선택해서 gradient를 계산  

polynomial regression: 특수한 관계 외에 (비선형 관계)적용하기 위한 방법.  
feature transformaton: 비선형 관계의 데이터를 선현회귀 모델에 적용하기 위해 적용. built in feature가 가장 쉽게 활용. 입력을 벡터로 변환  
Elastic net: 리지, 라쏘를 조합해서 사용.  
early stopping: 학습 곡선을 관찰하는 중에 validation error가 minimum에 도달하면 학습을 중단.  
logistic regression: 이진 분류에 사용되는 모델.  


----------------------1118-1 ---------------------------  
인터프리터블: 설명가능한  
impurity
- gini: 순수한지 only one class  
- entropy: 안정적인지. 무실서한 정도를 수치화 한 값.

regularization hypeparameters: 트리 구조는 과적합의 위험 존재.  
nonparametric model: 파라미터의 수가 미리 결정된 것이 아니라 데이터에 따라서 결정.  
prunning: 통계적 테스트에 따라 node를 잘라냄  


----------------- 1118-2 ----------------  
wisdom of the crowd: 한 명의 전문가보다 다수의 랜덤 사람들의 의견이 나을 수있음.  
ensemble: 다양성을 주기 위해 여러 모델 이용  
- hard voting classifier(=majority vote): 가장 많은 예측기가 분류한 클래스를 선택. 
매우 많은 수의 weak learner로 구성된 앙상블을 구성하고 learner가 다양성을 확보하면 정확도가 우수해짐.  
- soft voting: 모든 판별기가 확률을 출력하고 그 평균을 계산해서 가장 높은 확률값을 갖는 클래스를 출력.  

분산을 유지하면서 데이터 수를 늘리면 과학습을 방지.

- bagging(bootstrap aggregating): sampling with replacement. 샘플을 여러번 뽑아 각 모델을 집계. 
pasting이 좋을 수 있지만 bagging을 사용하는 이유는 적은 데이터로 재활용할 weak learner를 더 많이 확보가능하고 다양성이 너무 과하면 기본적으로 공통적인 데이터를 사용하기 위함. 
- pasting: smapling without replacement(일회용)  

bagging에서 랜덤 샘풀링뿐만아니라 feature도 램덤하게 선택  
- random patches method: 데이터와 feature 모두 랜덤하게 추출
- random subspace method: 모든 학습 데이터를 사용하지만 feature는 랜덤하게 선택(데이터 수가 적어서 사용)

랜덤성을 주는 이유는 다양성을 주기 위함.  
random forest: decision tree의 앙상블로 bagging을 사용하여 학습. 노드 분할시 가장 좋은 feature가 아닌 랜덤 feature 집합에서 가장 좋은 featrue를 기준으로 한다. 
루트노드로부터의 노드 깊이로 중요도를 확인.

boosting: 앙상블 기법의 하나. bagging과 다르게 순차적으로 학습(weak learner의 학습이 끝나면 다음 weak learner는 이전 잘못을 바로 잡는 방향으로 학습이 진행)
- adaboost(adaptive boosting): 실패한 데이터에 더 집중
- gradientboost: 이전 단계에서학습한 판별기의 residual error를 보정하는 형태로 현재 단계의 판별기를 학습.
- 예측 결과에 가중치를 부여하고 다른 모델에 영향을 주어 잘못된 분류 데이터에 대해 새로운 분류 규칙을 만드는 것을 반복하는 순차적 학습법.
- boosting이 bagging보다 에러 적으나 오래걸리고 과적합 가능성 높다.

### 지도학습
K-Nearest Neighbors  
• K개의 이웃한 데이터 포인트를 선택해서 많이 선택된 범주로 분류

Support Vector Machine  
• 범주 사이 마진(margin)을 최대화하는 hyperplane을 찾는 방식

Decision Tree   
• 나무 형태의 스무고개 형식 알고리즘  
• 가장 많은 정보를 얻을 수 있는 질문을 먼저 하도록!

random foreset:같은 데이터에 여러 개의 의사결정 나무를 사용하는 앙상블(ensemble) 기법  
• 부트스트랩(bootstrap) : 훈련 데이터에서 중복을 허용하여 같은 크기의 데이터셋을 만드는 과정  
• 배깅(bagging) : bootstrap aggregating의 약자로, 부트스트랩(bootstrap)을 통해 조금씩 다른 훈련
데이터에 대해 훈련된 기초 분류기(base learner)들을 결합(aggregating)  
• 포레스트를 구성하는 모든 트리들을 동일한 데이터셋으로만 훈련시키게 되면 트리들의 상관성(correlation)은 굉장히 커질 것. 
랜덤성(randomness)에 의해 트리들이 서로 조금씩 다른 특성 보유(일반화)  

#### 비지도학습
K-means: 데이터를 유사한 특성을 갖는 K개의 클러스터로 묶는 알고리즘 


---------------------------------------------------------------------
무작위성을 주는 기법들
- 각 트리의 학습데이터를 생성할 때, 전체 데이터에서 무작위로 중복을 허용하여 샘플을 선택하는 부트스트랩방법
- 각 노드에서 분할 시도할 때  가장 좋은 feature를 선택하는 대신, 랜덤 feature 부분집합 중 가장 좋은 feartue를 사용하는 방법으로 램덤성을 부여



